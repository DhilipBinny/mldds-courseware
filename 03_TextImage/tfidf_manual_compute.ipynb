{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "text processing - tfidf manual compute.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lisaong/mldds-courseware/blob/master/03_TextImage/tfidf_manual_compute.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZthx2dwLJeB",
        "colab_type": "text"
      },
      "source": [
        "# Text Processing\n",
        "\n",
        "This notebook covers:\n",
        "- Text Processing Techniques\n",
        "- Count vectorization\n",
        "- TFIDF computation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7CxXBGmLJeK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCPLNk0yLJf8",
        "colab_type": "text"
      },
      "source": [
        "## Text processing:\n",
        "- Tokenise: split text into words\n",
        "- Lemmatise: look at word form, considering noun, adjective, etc\n",
        "- Stem: get the word stem (bluntly chop off the end)\n",
        "\n",
        "### Goals:\n",
        "- Identify unique words\n",
        "- Avoid duplicating the same word form (e.g. cat, cats) in order to keep number of features small\n",
        "\n",
        "### Curse of Dimensionality:\n",
        "- 1 word is at least 1 feature (not considering N-grams - sequences of N words)\n",
        "- Reducing number of words will improve scalability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVCzOFiULJgD",
        "colab_type": "text"
      },
      "source": [
        "## NLTK\n",
        "\n",
        "We will exploring using NLTK (the Natural Language Processing Toolkit) to perform text pre-processing.\n",
        "\n",
        "(You should already have NLTK installed if you followed the Workshop Setup Instructions.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_DMhj7XLJgH",
        "colab_type": "code",
        "outputId": "1a291cf8-282d-4bb2-933e-e4ad2f06ce70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Download corpus for text pre-processing. These are not included in NLTK automatically because of file size.\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt') # tokenisation\n",
        "nltk.download('wordnet') # lemmatisation\n",
        "nltk.download('stopwords') # stop words"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeAbtsnTLJgi",
        "colab_type": "text"
      },
      "source": [
        "## Tokenise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omQSVXsXLJgl",
        "colab_type": "code",
        "outputId": "7f570a3e-f7cb-4a52-a291-4b453c59dcad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from nltk import word_tokenize\n",
        "\n",
        "text = 'Hello this is a test.'\n",
        "\n",
        "word_tokenize(text)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello', 'this', 'is', 'a', 'test', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd_8OH7VLJgr",
        "colab_type": "text"
      },
      "source": [
        "## Lemmatise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxXHmCMdLJgt",
        "colab_type": "code",
        "outputId": "d2fd9b4b-b3b1-4ecf-eb09-622fb797a4ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "text = 'he liked cats and dogs, and teaching machines to learn'\n",
        "\n",
        "# just tokenisation\n",
        "word_tokenize(text)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['he',\n",
              " 'liked',\n",
              " 'cats',\n",
              " 'and',\n",
              " 'dogs',\n",
              " ',',\n",
              " 'and',\n",
              " 'teaching',\n",
              " 'machines',\n",
              " 'to',\n",
              " 'learn']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQdXXdpILJgy",
        "colab_type": "code",
        "outputId": "87ede7e3-298c-43ec-acf9-c48e6fc63cbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# WordNet is a lexical database, it is used to\n",
        "# find the lemma of a word based on language rules (verb, etc)\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "text = 'he liked cats and dogs, and teaching machines to learn fasting mice women men man'\n",
        "\n",
        "# tokenise: breaks up sentence into words\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# lemmatise using list comprehension\n",
        "# WordNetLemmatizer\n",
        "wnl = WordNetLemmatizer()\n",
        "\n",
        "# result = [] \n",
        "# for t in tokens:\n",
        "#     print(wnl.lemmatize(t))\n",
        "#     result.append(wnl.lemmatize(t))\n",
        "\n",
        "# creates a list of lemmatised tokens\n",
        "# \n",
        "# text = 'he liked cats and dogs, and teaching machines to learn fasting mice men women'\n",
        "\n",
        "[wnl.lemmatize(t) for t in tokens]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['he',\n",
              " 'liked',\n",
              " 'cat',\n",
              " 'and',\n",
              " 'dog',\n",
              " ',',\n",
              " 'and',\n",
              " 'teaching',\n",
              " 'machine',\n",
              " 'to',\n",
              " 'learn',\n",
              " 'fasting',\n",
              " 'mouse',\n",
              " 'woman',\n",
              " 'men',\n",
              " 'man']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnP9CCiXLJg4",
        "colab_type": "text"
      },
      "source": [
        "## Stem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUSj4qIsLJg7",
        "colab_type": "code",
        "outputId": "a4250e04-1eb7-47a4-d986-6453f0bcac80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# Stemmer looks at word endings and chops it off\n",
        "# based on some rules, e.g: es -> e\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "text = 'he liked cats and dogs, and teaching teach machines to learn fasting mice men women'\n",
        "\n",
        "# tokenise\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# stemmer for English\n",
        "stm = SnowballStemmer('english')\n",
        "\n",
        "[stm.stem(t) for t in tokens]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['he',\n",
              " 'like',\n",
              " 'cat',\n",
              " 'and',\n",
              " 'dog',\n",
              " ',',\n",
              " 'and',\n",
              " 'teach',\n",
              " 'teach',\n",
              " 'machin',\n",
              " 'to',\n",
              " 'learn',\n",
              " 'fast',\n",
              " 'mice',\n",
              " 'men',\n",
              " 'women']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sF89bMrOLJhC",
        "colab_type": "text"
      },
      "source": [
        "## Stop words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tETUTvyjLJhD",
        "colab_type": "code",
        "outputId": "2d067d3f-e0e3-4b52-950f-b33a3e8b9bdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop = set(stopwords.words('english'))\n",
        "\n",
        "text = 'he liked cats and dogs, and teaching machines to learn'\n",
        "\n",
        "# lower case\n",
        "lower = text.lower()\n",
        "\n",
        "# tokenize\n",
        "tokens = word_tokenize(lower)\n",
        "\n",
        "# remove stop words\n",
        "[t for t in tokens if (t not in stop)]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['liked', 'cats', 'dogs', ',', 'teaching', 'machines', 'learn']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz2XQdJKLJhJ",
        "colab_type": "code",
        "outputId": "2907d93e-dc01-4d97-80d3-f187995c1287",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "stop"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okfZ9IjYLJhQ",
        "colab_type": "code",
        "outputId": "364949c7-91d3-481a-a2b4-c243ae6325db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(stop) # number of stop words"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMLkcAaqLJhW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add / remove words to stoplist\n",
        "# This changes the local copy, not the original stoplist\n",
        "\n",
        "stop.add('lah')\n",
        "stop.remove('because') # changes the stop list in-place\n",
        "                       # so running this cell again will return\n",
        "                       # KeyError"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHC1dEHhLJhj",
        "colab_type": "text"
      },
      "source": [
        "# Vectorise Text\n",
        "\n",
        "Vectorisation converts words into vectors of numbers\n",
        "\n",
        "Common ways:\n",
        "- By word count: CountVectorizer\n",
        "- By word and document frequency: TfidfVectorizer\n",
        "- By word vectors (gensim Word2Vec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkBjXJeFLJhm",
        "colab_type": "text"
      },
      "source": [
        "## Word Count Vectorisation\n",
        "\n",
        "* Words that are used more frequently get a higher count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Fa0IKC9LJhp",
        "colab_type": "code",
        "outputId": "118de9a0-5bdf-4c1f-acf1-290b989ae700",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "corpus = [\n",
        "   'This is the first document.',\n",
        "   'This document is the second document.',\n",
        "   'And this is the third one.',\n",
        "   'Is this the first document?',\n",
        "]\n",
        "\n",
        "# sklearn's stoplist, with unigram & bigram\n",
        "#countvec = CountVectorizer(ngram_range=(1, 2), stop_words='english')\n",
        "\n",
        "# sklearn stoplist is lousy, use nltk's\n",
        "countvec = CountVectorizer(ngram_range=(1, 2), stop_words=list(stop))\n",
        "result = countvec.fit_transform(corpus)\n",
        "print(result) # sparse matrix, (location) non-zero value"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 2)\t1\n",
            "  (0, 0)\t1\n",
            "  (0, 3)\t1\n",
            "  (1, 0)\t2\n",
            "  (1, 5)\t1\n",
            "  (1, 1)\t1\n",
            "  (1, 6)\t1\n",
            "  (2, 7)\t1\n",
            "  (2, 4)\t1\n",
            "  (2, 8)\t1\n",
            "  (3, 2)\t1\n",
            "  (3, 0)\t1\n",
            "  (3, 3)\t1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXQ4aXSkLJhy",
        "colab_type": "code",
        "outputId": "4555c8aa-df2c-4c89-aead-68aba7ae46e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# convert sparse matrix to dense matrix using todense()\n",
        "result.todense()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[1, 0, 1, 1, 0, 0, 0, 0, 0],\n",
              "        [2, 1, 0, 0, 0, 1, 1, 0, 0],\n",
              "        [0, 0, 0, 0, 1, 0, 0, 1, 1],\n",
              "        [1, 0, 1, 1, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLz6UE4VLJh6",
        "colab_type": "code",
        "outputId": "98fa9fdd-108a-4bde-ac81-0b10b53b2807",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# vocabulary\n",
        "countvec.get_feature_names()\n",
        "\n",
        "# create dataframe with count vectors as data\n",
        "# and vocabulary as headers\n",
        "\n",
        "# add the original text as the 'text column \n",
        "df = pd.DataFrame(result.todense(),\n",
        "             columns=countvec.get_feature_names())\n",
        "df['text'] = corpus\n",
        "df"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>document second</th>\n",
              "      <th>first</th>\n",
              "      <th>first document</th>\n",
              "      <th>one</th>\n",
              "      <th>second</th>\n",
              "      <th>second document</th>\n",
              "      <th>third</th>\n",
              "      <th>third one</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>This is the first document.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>This document is the second document.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>And this is the third one.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Is this the first document?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   document  document second  ...  third one                                   text\n",
              "0         1                0  ...          0            This is the first document.\n",
              "1         2                1  ...          0  This document is the second document.\n",
              "2         0                0  ...          1             And this is the third one.\n",
              "3         1                0  ...          0            Is this the first document?\n",
              "\n",
              "[4 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45R4zSNMLJh-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A32KmwDkLJiB",
        "colab_type": "text"
      },
      "source": [
        "## Word and Document Frequency (TF-IDF) Vectorisation\n",
        "\n",
        "- TF: Term Frequency: rewards words commonly used in a document\n",
        "- IDF: Inverse Document Frequency: penalises words commonly used in all documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2_zY9ABLJiC",
        "colab_type": "code",
        "outputId": "22c42b58-ba77-45cb-f4b4-b890997200eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "corpus = [\n",
        "   'This document is the first document.',\n",
        "   'This document is the second document.',\n",
        "   'And this is the third one.',\n",
        "   'Is this document the first document?',\n",
        "]\n",
        "\n",
        "# create vectoriser\n",
        "tfidf = TfidfVectorizer(ngram_range=(1, 2), stop_words=list(stop))\n",
        "\n",
        "# fit transform\n",
        "result = tfidf.fit_transform(corpus)\n",
        "\n",
        "# inspect matrix\n",
        "result.todense()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0.6829022 , 0.42176004, 0.        , 0.42176004, 0.42176004,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.59329727, 0.        , 0.46475741, 0.        , 0.        ,\n",
              "         0.        , 0.46475741, 0.46475741, 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.57735027, 0.        , 0.        , 0.57735027, 0.57735027],\n",
              "        [0.6829022 , 0.42176004, 0.        , 0.42176004, 0.42176004,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYK6jTWELJiF",
        "colab_type": "code",
        "outputId": "35bc0ca3-a977-475c-836e-0255f1b3c110",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# inspect vocabulary using get_feature_names()\n",
        "\n",
        "vocab = tfidf.get_feature_names()\n",
        "vocab"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['document',\n",
              " 'document first',\n",
              " 'document second',\n",
              " 'first',\n",
              " 'first document',\n",
              " 'one',\n",
              " 'second',\n",
              " 'second document',\n",
              " 'third',\n",
              " 'third one']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLoeMtvsLJiJ",
        "colab_type": "code",
        "outputId": "5e7bc834-c1c6-4c7c-c5f3-b209492afbf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# create dataframe with count vectors as data\n",
        "# and vocabulary as headers\n",
        "# remember to convert vectors from sparse to dense matrix\n",
        "\n",
        "# add the original text as the 'text column \n",
        "df = pd.DataFrame(result.todense(),\n",
        "             columns=vocab)\n",
        "\n",
        "# add the original text as the 'text column \n",
        "df['text'] = corpus\n",
        "df"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>document first</th>\n",
              "      <th>document second</th>\n",
              "      <th>first</th>\n",
              "      <th>first document</th>\n",
              "      <th>one</th>\n",
              "      <th>second</th>\n",
              "      <th>second document</th>\n",
              "      <th>third</th>\n",
              "      <th>third one</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.682902</td>\n",
              "      <td>0.42176</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.42176</td>\n",
              "      <td>0.42176</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>This document is the first document.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.593297</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.464757</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.464757</td>\n",
              "      <td>0.464757</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>This document is the second document.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.57735</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.57735</td>\n",
              "      <td>0.57735</td>\n",
              "      <td>And this is the third one.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.682902</td>\n",
              "      <td>0.42176</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.42176</td>\n",
              "      <td>0.42176</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>Is this document the first document?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   document  document first  ...  third one                                   text\n",
              "0  0.682902         0.42176  ...    0.00000   This document is the first document.\n",
              "1  0.593297         0.00000  ...    0.00000  This document is the second document.\n",
              "2  0.000000         0.00000  ...    0.57735             And this is the third one.\n",
              "3  0.682902         0.42176  ...    0.00000   Is this document the first document?\n",
              "\n",
              "[4 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RpJJJTOLJiM",
        "colab_type": "code",
        "outputId": "9d63d286-7c93-478f-ed7d-95b302549d62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Computing TFIDF manually to check the values above\n",
        "\n",
        "# first, we examine the settings used for our TFIDF vectorizer\n",
        "tfidf"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
              "                min_df=1, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
              "                smooth_idf=True,\n",
              "                stop_words=['over', 'wouldn', 'but', 'at', 'can', 'they', 'don',\n",
              "                            \"you've\", 'you', 'most', 'herself', 'how', 'to',\n",
              "                            'were', 'during', 'has', \"don't\", 'having',\n",
              "                            'itself', 'down', 'that', 'hers', 'had', 'an', 't',\n",
              "                            'or', 'll', 'yourself', 'lah', \"isn't\", ...],\n",
              "                strip_accents=None, sublinear_tf=False,\n",
              "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
              "                vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fl623qxkLJiQ",
        "colab_type": "text"
      },
      "source": [
        "Based on https://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting, the equation used is:\n",
        "\n",
        "$\\text{tf-idf(t,d)}=\\text{tf(t,d)} \\times \\text{idf(t)}$\n",
        "\n",
        "Where:\n",
        "\n",
        "$\\text{idf}(t) = \\log{\\frac{n}{1+\\text{df}(t)}}$\n",
        "\n",
        "When smooth_idf=True, the TFIDF computed tries to avoid zero values by adding a 1:\n",
        "\n",
        "$\\text{idf}(t) = \\log{\\frac{1 + n}{1+\\text{df}(t)}} + 1$\n",
        "\n",
        "Where $n$ is the total number of documents in the document set, and $\\text{df}(t)$ is the number of documents in the document set that contain term $t$. The resulting tf-idf vectors are then normalized by the Euclidean norm:\n",
        "\n",
        "$v_{norm} = \\frac{v}{||v||_2} = \\frac{v}{\\sqrt{v{_1}^2 +\n",
        "v{_2}^2 + \\dots + v{_n}^2}}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT0suuTvLJiR",
        "colab_type": "code",
        "outputId": "537093f1-c011-4d31-ad22-0bc336ab8398",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "corpus"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This document is the first document.',\n",
              " 'This document is the second document.',\n",
              " 'And this is the third one.',\n",
              " 'Is this document the first document?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOfAtWXBLJiW",
        "colab_type": "code",
        "outputId": "5de21c67-1e4a-4d8c-c4b6-5e4eb0644dc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# term frequency\n",
        "countvec = CountVectorizer(ngram_range=(1, 2), stop_words=list(stop))\n",
        "\n",
        "tf_sparse = countvec.fit_transform(corpus)\n",
        "tf = tf_sparse.todense()\n",
        "tf"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[2, 1, 0, 1, 1, 0, 0, 0, 0, 0],\n",
              "        [2, 0, 1, 0, 0, 0, 1, 1, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 1, 0, 0, 1, 1],\n",
              "        [2, 1, 0, 1, 1, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLBDe_GbLJic",
        "colab_type": "code",
        "outputId": "4086740d-d7b4-4ed5-80b4-e3d7af7e19f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# document frequency\n",
        "# the number of documents in the document set that contain term t\n",
        "# can be computed by inspecting how many non-zero counts there are in each column\n",
        "\n",
        "df = (tf > 0).sum(axis=0)\n",
        "df"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[3, 2, 1, 2, 2, 1, 1, 1, 1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihkjdtqKLJio",
        "colab_type": "code",
        "outputId": "4fbb4740-a58f-482a-a13d-c391d382f98b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n = len(corpus)\n",
        "n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEQEIlfTLJiv",
        "colab_type": "code",
        "outputId": "c5850472-8f27-4a2b-942a-19ee6535e248",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# inverse document frequency (smooth_idf=True version)\n",
        "idf = np.log(n / (1 + df)) + 1\n",
        "idf"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[1.        , 1.28768207, 1.69314718, 1.28768207, 1.28768207,\n",
              "         1.69314718, 1.69314718, 1.69314718, 1.69314718, 1.69314718]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX9wUlJ9LJi1",
        "colab_type": "code",
        "outputId": "63e89ced-0917-446f-f58b-2dedb8b3f1aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# tf x idf\n",
        "# element-wise multiply\n",
        "tfidf_raw = np.multiply(tf, idf)\n",
        "pd.DataFrame(tfidf_raw, columns=vocab)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>document first</th>\n",
              "      <th>document second</th>\n",
              "      <th>first</th>\n",
              "      <th>first document</th>\n",
              "      <th>one</th>\n",
              "      <th>second</th>\n",
              "      <th>second document</th>\n",
              "      <th>third</th>\n",
              "      <th>third one</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>1.287682</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.287682</td>\n",
              "      <td>1.287682</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.693147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.693147</td>\n",
              "      <td>1.693147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.693147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.693147</td>\n",
              "      <td>1.693147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.0</td>\n",
              "      <td>1.287682</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.287682</td>\n",
              "      <td>1.287682</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   document  document first  ...     third  third one\n",
              "0       2.0        1.287682  ...  0.000000   0.000000\n",
              "1       2.0        0.000000  ...  0.000000   0.000000\n",
              "2       0.0        0.000000  ...  1.693147   1.693147\n",
              "3       2.0        1.287682  ...  0.000000   0.000000\n",
              "\n",
              "[4 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBzHAUpnLJi9",
        "colab_type": "code",
        "outputId": "ae801350-0eb2-4e01-9054-0b1ed7bfc658",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# compute euclidean norm for each document\n",
        "v_norm = np.linalg.norm(tfidf_raw, axis=1)\n",
        "v_norm"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.99572618, 3.54968198, 2.93261694, 2.99572618])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EVLzY6vLJjB",
        "colab_type": "code",
        "outputId": "c53bd76e-a003-4b42-b989-88bd82d3640c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# [:, None] allows tfidf_raw to be divided by each vector element\n",
        "# for example, first row will be divided by v_norm[0], second row by v_norm[1], etc\n",
        "tfidf = tfidf_raw / v_norm[:, None]\n",
        "tfidf"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0.66761776, 0.42983971, 0.        , 0.42983971, 0.42983971,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.56343076, 0.        , 0.4769856 , 0.        , 0.        ,\n",
              "         0.        , 0.4769856 , 0.4769856 , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.57735027, 0.        , 0.        , 0.57735027, 0.57735027],\n",
              "        [0.66761776, 0.42983971, 0.        , 0.42983971, 0.42983971,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP1A1arhLJjJ",
        "colab_type": "code",
        "outputId": "75dc1c55-6e9d-4d44-d209-fd040c029e8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# compare with TfidfVectorizer's output\n",
        "result.todense()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0.6829022 , 0.42176004, 0.        , 0.42176004, 0.42176004,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.59329727, 0.        , 0.46475741, 0.        , 0.        ,\n",
              "         0.        , 0.46475741, 0.46475741, 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.57735027, 0.        , 0.        , 0.57735027, 0.57735027],\n",
              "        [0.6829022 , 0.42176004, 0.        , 0.42176004, 0.42176004,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzSVhMuFLJjO",
        "colab_type": "code",
        "outputId": "6148bd92-d38e-4d32-955b-7e7e5a0c265c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# the values are within +/-0.02, possibly due to floating point rounding error\n",
        "abs(tfidf - result.todense())"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0.01528444, 0.00807967, 0.        , 0.00807967, 0.00807967,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.02986651, 0.        , 0.01222819, 0.        , 0.        ,\n",
              "         0.        , 0.01222819, 0.01222819, 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.01528444, 0.00807967, 0.        , 0.00807967, 0.00807967,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KLTro19LJjT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C2orQjTLJjZ",
        "colab_type": "text"
      },
      "source": [
        "## Word2Vec\n",
        "\n",
        "Word2Vec generates word-vectors where vectors close together in vector space have similar meanings based on context, and word-vectors distant to each other have differing meanings.\n",
        "\n",
        "### Gensim\n",
        "\n",
        "Gensim is a Python library to train word vectors, and to load pre-trained word vectors.\n",
        "\n",
        "(You should already have Gensim installed if you followed the Workshop Setup Instructions.)\n",
        "\n",
        "https://radimrehurek.com/gensim/models/word2vec.html\n",
        "https://radimrehurek.com/gensim/models/keyedvectors.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9qi6NRZLJja",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYrOed0VPms8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install gensim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7wy-w93LJja",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "379413a0-6d37-4901-dd1f-e914f6c369e2"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "corpus = [\n",
        "    'Dashing through the snow',\n",
        "    'In a one-horse open sleigh',\n",
        "    'Over the fields we go',\n",
        "    'Laughing all the way',\n",
        "    'Bells on bob-tail ring',\n",
        "    'Making spirits bright',\n",
        "    'What fun it is to ride and sing a sleighing song tonight'\n",
        "]\n",
        "\n",
        "# split text into words\n",
        "corpus_tokens = [word_tokenize(doc.lower()) for doc in corpus]\n",
        "\n",
        "vector_size=10 # vector representation (typically about 50-100 for larger vocabs)\n",
        "\n",
        "window_size=3 # how many words to see around it (depending on task)\n",
        "\n",
        "# train\n",
        "word2vec = Word2Vec(corpus_tokens, size=vector_size, \n",
        "                    window=window_size,\n",
        "                    min_count=1, workers=4)\n",
        "\n",
        "word2vec.save('word2vec.model') # save for use later"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LK-iMlxxLJjd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a5d7e64c-cd5e-470e-d480-02ff6d58b8c1"
      },
      "source": [
        "# lookup vector using wv\n",
        "\n",
        "model = Word2Vec.load('word2vec.model')"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRKT6JwxRxGG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "295c532b-fb4d-4394-fe18-055b54f1c76f"
      },
      "source": [
        "model.wv['snow']"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.00251603,  0.04430296, -0.02943466, -0.00134141, -0.03735583,\n",
              "        0.01622982, -0.04263984, -0.0040435 , -0.00726846,  0.01236074],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwfmq4iHLJjg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "ccc3c75b-d708-4f68-fe0e-ab9bf53397f6"
      },
      "source": [
        "# find similar words using most_similar\n",
        "\n",
        "model.wv.most_similar('snow')"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('laughing', 0.46315237879753113),\n",
              " ('through', 0.4586874842643738),\n",
              " ('all', 0.45076000690460205),\n",
              " ('dashing', 0.4005179703235626),\n",
              " ('it', 0.35689616203308105),\n",
              " ('we', 0.33617711067199707),\n",
              " ('ring', 0.2503301501274109),\n",
              " ('go', 0.20174315571784973),\n",
              " ('what', 0.18450412154197693),\n",
              " ('way', 0.18004260957241058)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGqZVSH2LJjj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6da3ba87-3da0-4073-9d9a-bb2413b303c3"
      },
      "source": [
        "# inspect vocabulary using wv.vocab\n",
        "\n",
        "model.wv.vocab.keys()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['dashing', 'through', 'the', 'snow', 'in', 'a', 'one-horse', 'open', 'sleigh', 'over', 'fields', 'we', 'go', 'laughing', 'all', 'way', 'bells', 'on', 'bob-tail', 'ring', 'making', 'spirits', 'bright', 'what', 'fun', 'it', 'is', 'to', 'ride', 'and', 'sing', 'sleighing', 'song', 'tonight'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9cnIIG3LJjs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "15842334-c961-4e57-8acb-3c7607f1a797"
      },
      "source": [
        "# get word vectors using vectors\n",
        "\n",
        "model.wv.vectors"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.02024841, -0.02363075, -0.0067077 ,  0.01714315,  0.01189275,\n",
              "        -0.04451837,  0.04471996,  0.0116303 ,  0.03900393, -0.02928073],\n",
              "       [-0.03840334, -0.02825641,  0.01018477, -0.01077155,  0.01540786,\n",
              "        -0.0020289 ,  0.01161858, -0.03156778, -0.0238294 , -0.02631742],\n",
              "       [-0.00818824,  0.04676739, -0.04089574,  0.00293907,  0.00579027,\n",
              "         0.02044639,  0.02290519, -0.02465931,  0.0118738 ,  0.00279095],\n",
              "       [-0.0039688 ,  0.04832843, -0.03159709,  0.00406955, -0.04520088,\n",
              "         0.00126436,  0.01330342,  0.00450369,  0.04253701, -0.034617  ],\n",
              "       [ 0.00251603,  0.04430296, -0.02943466, -0.00134141, -0.03735583,\n",
              "         0.01622982, -0.04263984, -0.0040435 , -0.00726846,  0.01236074],\n",
              "       [-0.03640911, -0.03708036, -0.00702204, -0.04988885, -0.04708905,\n",
              "        -0.03888847,  0.04616447,  0.04525517,  0.04266737, -0.02168377],\n",
              "       [ 0.03159136, -0.04023651, -0.02139726, -0.02771721,  0.04980505,\n",
              "         0.01695251,  0.04904992,  0.01530724,  0.02209809, -0.04594931],\n",
              "       [-0.03527501, -0.0105756 , -0.01545606, -0.01384903,  0.0049733 ,\n",
              "        -0.04939621,  0.00801609, -0.04635264,  0.00463717,  0.03903132],\n",
              "       [ 0.00657282, -0.04188105, -0.04307052,  0.00969836,  0.03862516,\n",
              "        -0.02232214,  0.01956511, -0.04319038,  0.03746392, -0.04005827],\n",
              "       [-0.0162541 ,  0.00696331,  0.04583511, -0.01674099,  0.02541358,\n",
              "         0.02726082,  0.02764681, -0.00308779,  0.04704256,  0.02187283],\n",
              "       [-0.0457368 , -0.02675663, -0.04137333, -0.01020245, -0.03304437,\n",
              "         0.04682695,  0.02746417,  0.04278667,  0.03263406,  0.02135892],\n",
              "       [ 0.03073413,  0.03970593,  0.0418059 ,  0.03937019, -0.03506212,\n",
              "         0.03509051, -0.03337191, -0.02185121,  0.04696366, -0.03668891],\n",
              "       [-0.00225893,  0.03050826,  0.04350106,  0.04401978, -0.04453486,\n",
              "        -0.00132991, -0.0084369 , -0.03069527, -0.00473885, -0.04474378],\n",
              "       [-0.01409112,  0.04750187,  0.0386356 , -0.03379633, -0.02553078,\n",
              "         0.03402286, -0.03436822, -0.02792623,  0.03761224,  0.00061774],\n",
              "       [ 0.00781089,  0.04478922, -0.03794087, -0.02114667, -0.00549667,\n",
              "        -0.04438287, -0.02559654, -0.02439619,  0.03967539, -0.00864632],\n",
              "       [-0.00887286,  0.0450725 , -0.03732522, -0.01604248, -0.00153265,\n",
              "        -0.01398946,  0.04247582, -0.04349661,  0.04202658,  0.04777982],\n",
              "       [-0.01818679, -0.00885146,  0.00279512,  0.03856863,  0.0151565 ,\n",
              "        -0.03088056, -0.03920541, -0.03979346, -0.01843439, -0.01894999],\n",
              "       [-0.01487483,  0.01544945,  0.04305301,  0.04892145,  0.00114421,\n",
              "        -0.01118053, -0.03574175,  0.00451844,  0.01035077,  0.03393955],\n",
              "       [-0.02273411, -0.01270891,  0.02313054,  0.02922297,  0.00604456,\n",
              "        -0.04464985,  0.01938165, -0.02442168, -0.0321305 ,  0.01310346],\n",
              "       [ 0.04782389,  0.00683404, -0.04523922, -0.03318852, -0.00738293,\n",
              "        -0.04250802,  0.00206664, -0.04870106, -0.03072424,  0.04650199],\n",
              "       [ 0.01281051,  0.04630319,  0.02673768,  0.02130608,  0.02363564,\n",
              "        -0.03499069,  0.0226898 ,  0.00308064,  0.04744083,  0.04404892],\n",
              "       [ 0.02121571, -0.03691551, -0.0464157 ,  0.01886059, -0.02818923,\n",
              "         0.00018367,  0.04396192,  0.04246411, -0.02507498,  0.02005438],\n",
              "       [-0.02327432, -0.00983385,  0.03208892,  0.02352516,  0.01955506,\n",
              "         0.02135678, -0.03602025, -0.00387409, -0.03373512, -0.04139324],\n",
              "       [-0.03524437,  0.04057879,  0.01179417,  0.01613277,  0.01125319,\n",
              "         0.00954501, -0.00225807,  0.01964486, -0.02877783, -0.01913372],\n",
              "       [ 0.02745169, -0.02203379,  0.02889988,  0.03067053,  0.0477457 ,\n",
              "        -0.00442237, -0.03401187, -0.00620667,  0.02236844,  0.00362671],\n",
              "       [ 0.01612474,  0.04524354,  0.04559399, -0.02743839, -0.00254036,\n",
              "         0.03236012, -0.04631984,  0.0428857 ,  0.04114013,  0.03702469],\n",
              "       [ 0.02655297,  0.02511931,  0.03022916,  0.00270219, -0.02108546,\n",
              "        -0.02902167,  0.02359278, -0.00640556,  0.01865557,  0.01919932],\n",
              "       [ 0.00873113, -0.01188441,  0.04295298,  0.02139677,  0.0248022 ,\n",
              "         0.04422079, -0.00725596, -0.03088255, -0.01902042,  0.03075291],\n",
              "       [-0.04577525,  0.01709589, -0.00830893,  0.02878097,  0.03214482,\n",
              "         0.02828425,  0.01003131,  0.02668469,  0.00625687, -0.0150468 ],\n",
              "       [ 0.03790291, -0.040165  , -0.04202752,  0.02592429,  0.01371606,\n",
              "         0.01946287, -0.04713174,  0.0079064 ,  0.02984063, -0.01077971],\n",
              "       [-0.04376176,  0.02602307,  0.01657295, -0.00346807,  0.03629731,\n",
              "        -0.03572024,  0.03734716, -0.00512422, -0.0435592 , -0.03468399],\n",
              "       [ 0.04051419,  0.02890378, -0.00890278, -0.03211914,  0.00922307,\n",
              "         0.02030056,  0.01104291,  0.0485941 , -0.02992163,  0.00263775],\n",
              "       [ 0.02764164, -0.01580638,  0.0003746 ,  0.04642361,  0.02485122,\n",
              "        -0.00260699,  0.02590467,  0.04817306, -0.03271174, -0.00571678],\n",
              "       [-0.00330951, -0.04325883, -0.01270822,  0.0118857 , -0.01792927,\n",
              "         0.03171911,  0.04224816, -0.04862902, -0.01208927,  0.01766374]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7BwKEUzLJjy",
        "colab_type": "code",
        "outputId": "89344810-06be-4a62-9044-2ccfab5d01b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        }
      },
      "source": [
        "# To explore word vectors, you can plot them in 2d space\n",
        "# (Notice how useful PCA is?)\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "wv_2d = pca.fit_transform(word2vec.wv.vectors)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "# scatter plot\n",
        "ax.scatter(wv_2d[:, 0], wv_2d[:, 1])\n",
        "\n",
        "# annotate each point using the words\n",
        "for i, word in enumerate(model.wv.vocab):\n",
        "    ax.annotate(word, (wv_2d[i, 0], wv_2d[i, 1]))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAHSCAYAAACkQxwNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPbNE4u9LJj2",
        "colab_type": "text"
      },
      "source": [
        "### Pre-trained Word2Vec models\n",
        "\n",
        "Instead of training your own word2vec, you can alternatively load the (large!) pre-trained models\n",
        "\n",
        "https://github.com/RaRe-Technologies/gensim-data\n",
        "\n",
        "These are most commonly used when training Neural Networks, because scikit-learn cannot handle non-scalar features well.  :("
      ]
    }
  ]
}