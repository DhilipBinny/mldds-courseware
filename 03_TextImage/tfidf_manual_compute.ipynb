{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "text processing - tfidf manual compute.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lisaong/mldds-courseware/blob/master/03_TextImage/tfidf_manual_compute.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZthx2dwLJeB",
        "colab_type": "text"
      },
      "source": [
        "# Text Processing\n",
        "\n",
        "This notebook covers:\n",
        "- Text Processing Techniques\n",
        "- Count vectorization\n",
        "- TFIDF computation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7CxXBGmLJeK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCPLNk0yLJf8",
        "colab_type": "text"
      },
      "source": [
        "## Text processing:\n",
        "- Tokenise: split text into words\n",
        "- Lemmatise: look at word form, considering noun, adjective, etc\n",
        "- Stem: get the word stem (bluntly chop off the end)\n",
        "\n",
        "### Goals:\n",
        "- Identify unique words\n",
        "- Avoid duplicating the same word form (e.g. cat, cats) in order to keep number of features small\n",
        "\n",
        "### Curse of Dimensionality:\n",
        "- 1 word is at least 1 feature (not considering N-grams - sequences of N words)\n",
        "- Reducing number of words will improve scalability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVCzOFiULJgD",
        "colab_type": "text"
      },
      "source": [
        "## NLTK\n",
        "\n",
        "We will exploring using NLTK (the Natural Language Processing Toolkit) to perform text pre-processing.\n",
        "\n",
        "(You should already have NLTK installed if you followed the Workshop Setup Instructions.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_DMhj7XLJgH",
        "colab_type": "code",
        "outputId": "25d91aef-e120-4fdd-91e9-50bac104f87b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "# Download corpus for text pre-processing. These are not included in NLTK automatically because of file size.\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt') # tokenisation\n",
        "nltk.download('wordnet') # lemmatisation\n",
        "nltk.download('stopwords') # stop words"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeAbtsnTLJgi",
        "colab_type": "text"
      },
      "source": [
        "## Tokenise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omQSVXsXLJgl",
        "colab_type": "code",
        "outputId": "8d4d6037-9ec4-4617-a70f-31408f228ec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from nltk import word_tokenize\n",
        "\n",
        "text = 'Hello this is a test.'\n",
        "\n",
        "word_tokenize(text)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello', 'this', 'is', 'a', 'test', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd_8OH7VLJgr",
        "colab_type": "text"
      },
      "source": [
        "## Lemmatise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxXHmCMdLJgt",
        "colab_type": "code",
        "outputId": "cb8fa87b-4cdd-48bd-c01e-b65985ee1f20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "text = 'he liked cats and dogs, and teaching machines to learn'\n",
        "\n",
        "# just tokenisation\n",
        "word_tokenize(text)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['he',\n",
              " 'liked',\n",
              " 'cats',\n",
              " 'and',\n",
              " 'dogs',\n",
              " ',',\n",
              " 'and',\n",
              " 'teaching',\n",
              " 'machines',\n",
              " 'to',\n",
              " 'learn']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQdXXdpILJgy",
        "colab_type": "code",
        "outputId": "5d878f0e-ad33-466b-cdd9-182ea65c0857",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        }
      },
      "source": [
        "# WordNet is a lexical database, it is used to\n",
        "# find the lemma of a word based on language rules (verb, etc)\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "text = 'he liked cats and dogs, and teaching machines to learn fasting mice women men man'\n",
        "\n",
        "# tokenise: breaks up sentence into words\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# lemmatise using list comprehension\n",
        "# WordNetLemmatizer\n",
        "wnl = WordNetLemmatizer()\n",
        "\n",
        "# result = [] \n",
        "# for t in tokens:\n",
        "#     print(wnl.lemmatize(t))\n",
        "#     result.append(wnl.lemmatize(t))\n",
        "\n",
        "# creates a list of lemmatised tokens\n",
        "# \n",
        "# text = 'he liked cats and dogs, and teaching machines to learn fasting mice men women'\n",
        "\n",
        "[wnl.lemmatize(t) for t in tokens]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['he',\n",
              " 'liked',\n",
              " 'cat',\n",
              " 'and',\n",
              " 'dog',\n",
              " ',',\n",
              " 'and',\n",
              " 'teaching',\n",
              " 'machine',\n",
              " 'to',\n",
              " 'learn',\n",
              " 'fasting',\n",
              " 'mouse',\n",
              " 'woman',\n",
              " 'men',\n",
              " 'man']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnP9CCiXLJg4",
        "colab_type": "text"
      },
      "source": [
        "## Stem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUSj4qIsLJg7",
        "colab_type": "code",
        "outputId": "e3bd927d-4a1c-4f7f-d57d-ca82808dfd36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        }
      },
      "source": [
        "# Stemmer looks at word endings and chops it off\n",
        "# based on some rules, e.g: es -> e\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "text = 'he liked cats and dogs, and teaching teach machines to learn fasting mice men women'\n",
        "\n",
        "# tokenise\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# stemmer for English\n",
        "stm = SnowballStemmer('english')\n",
        "\n",
        "[stm.stem(t) for t in tokens]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['he',\n",
              " 'like',\n",
              " 'cat',\n",
              " 'and',\n",
              " 'dog',\n",
              " ',',\n",
              " 'and',\n",
              " 'teach',\n",
              " 'teach',\n",
              " 'machin',\n",
              " 'to',\n",
              " 'learn',\n",
              " 'fast',\n",
              " 'mice',\n",
              " 'men',\n",
              " 'women']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sF89bMrOLJhC",
        "colab_type": "text"
      },
      "source": [
        "## Stop words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tETUTvyjLJhD",
        "colab_type": "code",
        "outputId": "fa92f5c3-a75c-412d-83c3-354731a6bee7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop = set(stopwords.words('english'))\n",
        "\n",
        "text = 'he liked cats and dogs, and teaching machines to learn'\n",
        "\n",
        "# lower case\n",
        "lower = text.lower()\n",
        "\n",
        "# tokenize\n",
        "tokens = word_tokenize(lower)\n",
        "\n",
        "# remove stop words\n",
        "[t for t in tokens if (t not in stop)]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['liked', 'cats', 'dogs', ',', 'teaching', 'machines', 'learn']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz2XQdJKLJhJ",
        "colab_type": "code",
        "outputId": "b02069cd-0c07-4524-f82d-37cb12185404",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "stop"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okfZ9IjYLJhQ",
        "colab_type": "code",
        "outputId": "c5fadd11-80b4-4377-b192-41433ca2de01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(stop) # number of stop words"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMLkcAaqLJhW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add / remove words to stoplist\n",
        "# This changes the local copy, not the original stoplist\n",
        "\n",
        "stop.add('lah')\n",
        "stop.remove('because') # changes the stop list in-place\n",
        "                       # so running this cell again will return\n",
        "                       # KeyError"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHC1dEHhLJhj",
        "colab_type": "text"
      },
      "source": [
        "# Vectorise Text\n",
        "\n",
        "Vectorisation converts words into vectors of numbers\n",
        "\n",
        "Common ways:\n",
        "- By word count: CountVectorizer\n",
        "- By word and document frequency: TfidfVectorizer\n",
        "- By word vectors (gensim Word2Vec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkBjXJeFLJhm",
        "colab_type": "text"
      },
      "source": [
        "## Word Count Vectorisation\n",
        "\n",
        "* Words that are used more frequently get a higher count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Fa0IKC9LJhp",
        "colab_type": "code",
        "outputId": "34fd3e3c-4a04-4d88-eec4-6bccaea36a19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "corpus = [\n",
        "   'This is the first document.',\n",
        "   'This document is the second document.',\n",
        "   'And this is the third one.',\n",
        "   'Is this the first document?',\n",
        "]\n",
        "\n",
        "# sklearn's stoplist, with unigram & bigram\n",
        "#countvec = CountVectorizer(ngram_range=(1, 2), stop_words='english')\n",
        "\n",
        "# sklearn stoplist is lousy, use nltk's\n",
        "countvec = CountVectorizer(ngram_range=(1, 2), stop_words=list(stop))\n",
        "result = countvec.fit_transform(corpus)\n",
        "print(result) # sparse matrix, (location) non-zero value"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 2)\t1\n",
            "  (0, 0)\t1\n",
            "  (0, 3)\t1\n",
            "  (1, 0)\t2\n",
            "  (1, 5)\t1\n",
            "  (1, 1)\t1\n",
            "  (1, 6)\t1\n",
            "  (2, 7)\t1\n",
            "  (2, 4)\t1\n",
            "  (2, 8)\t1\n",
            "  (3, 2)\t1\n",
            "  (3, 0)\t1\n",
            "  (3, 3)\t1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXQ4aXSkLJhy",
        "colab_type": "code",
        "outputId": "0deaa55f-b24d-4538-fa58-bed2634b2cc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "# convert sparse matrix to dense matrix using todense()\n",
        "result.todense()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[1, 0, 1, 1, 0, 0, 0, 0, 0],\n",
              "        [2, 1, 0, 0, 0, 1, 1, 0, 0],\n",
              "        [0, 0, 0, 0, 1, 0, 0, 1, 1],\n",
              "        [1, 0, 1, 1, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLz6UE4VLJh6",
        "colab_type": "code",
        "outputId": "5e2a0c0e-d6e0-4ff0-b472-98916b45bdd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "# vocabulary\n",
        "countvec.get_feature_names()\n",
        "\n",
        "# create dataframe with count vectors as data\n",
        "# and vocabulary as headers\n",
        "\n",
        "# add the original text as the 'text column \n",
        "df = pd.DataFrame(result.todense(),\n",
        "             columns=countvec.get_feature_names())\n",
        "df['text'] = corpus\n",
        "df"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>document second</th>\n",
              "      <th>first</th>\n",
              "      <th>first document</th>\n",
              "      <th>one</th>\n",
              "      <th>second</th>\n",
              "      <th>second document</th>\n",
              "      <th>third</th>\n",
              "      <th>third one</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>This is the first document.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>This document is the second document.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>And this is the third one.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Is this the first document?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   document  document second  ...  third one                                   text\n",
              "0         1                0  ...          0            This is the first document.\n",
              "1         2                1  ...          0  This document is the second document.\n",
              "2         0                0  ...          1             And this is the third one.\n",
              "3         1                0  ...          0            Is this the first document?\n",
              "\n",
              "[4 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45R4zSNMLJh-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A32KmwDkLJiB",
        "colab_type": "text"
      },
      "source": [
        "## Word and Document Frequency (TF-IDF) Vectorisation\n",
        "\n",
        "- TF: Term Frequency: rewards words commonly used in a document\n",
        "- IDF: Inverse Document Frequency: penalises words commonly used in all documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2_zY9ABLJiC",
        "colab_type": "code",
        "outputId": "caa3802e-1e96-4278-b15a-603ead2c5121",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "corpus = [\n",
        "   'This document is the first document.',\n",
        "   'This document is the second document.',\n",
        "   'And this is the third one.',\n",
        "   'Is this document the first document?',\n",
        "]\n",
        "\n",
        "# create vectoriser\n",
        "tfidf = TfidfVectorizer(ngram_range=(1, 2), stop_words=list(stop))\n",
        "\n",
        "# fit transform\n",
        "result = tfidf.fit_transform(corpus)\n",
        "\n",
        "# inspect matrix\n",
        "result.todense()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0.6829022 , 0.42176004, 0.        , 0.42176004, 0.42176004,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.59329727, 0.        , 0.46475741, 0.        , 0.        ,\n",
              "         0.        , 0.46475741, 0.46475741, 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.57735027, 0.        , 0.        , 0.57735027, 0.57735027],\n",
              "        [0.6829022 , 0.42176004, 0.        , 0.42176004, 0.42176004,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYK6jTWELJiF",
        "colab_type": "code",
        "outputId": "197291aa-9a8b-42f9-fcfc-8133eb454022",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "# inspect vocabulary using get_feature_names()\n",
        "\n",
        "vocab = tfidf.get_feature_names()\n",
        "vocab"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['document',\n",
              " 'document first',\n",
              " 'document second',\n",
              " 'first',\n",
              " 'first document',\n",
              " 'one',\n",
              " 'second',\n",
              " 'second document',\n",
              " 'third',\n",
              " 'third one']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLoeMtvsLJiJ",
        "colab_type": "code",
        "outputId": "0f675db7-85c5-4f6e-dda1-01ed16c6d0f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "# create dataframe with count vectors as data\n",
        "# and vocabulary as headers\n",
        "# remember to convert vectors from sparse to dense matrix\n",
        "\n",
        "# add the original text as the 'text column \n",
        "df = pd.DataFrame(result.todense(),\n",
        "             columns=vocab)\n",
        "\n",
        "# add the original text as the 'text column \n",
        "df['text'] = corpus\n",
        "df"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>document first</th>\n",
              "      <th>document second</th>\n",
              "      <th>first</th>\n",
              "      <th>first document</th>\n",
              "      <th>one</th>\n",
              "      <th>second</th>\n",
              "      <th>second document</th>\n",
              "      <th>third</th>\n",
              "      <th>third one</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.682902</td>\n",
              "      <td>0.42176</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.42176</td>\n",
              "      <td>0.42176</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>This document is the first document.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.593297</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.464757</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.464757</td>\n",
              "      <td>0.464757</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>This document is the second document.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.57735</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.57735</td>\n",
              "      <td>0.57735</td>\n",
              "      <td>And this is the third one.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.682902</td>\n",
              "      <td>0.42176</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.42176</td>\n",
              "      <td>0.42176</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>Is this document the first document?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   document  document first  ...  third one                                   text\n",
              "0  0.682902         0.42176  ...    0.00000   This document is the first document.\n",
              "1  0.593297         0.00000  ...    0.00000  This document is the second document.\n",
              "2  0.000000         0.00000  ...    0.57735             And this is the third one.\n",
              "3  0.682902         0.42176  ...    0.00000   Is this document the first document?\n",
              "\n",
              "[4 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RpJJJTOLJiM",
        "colab_type": "code",
        "outputId": "b3c26429-87b5-4ec4-d17b-2faff2b1008f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "source": [
        "# Computing TFIDF manually to check the values above\n",
        "\n",
        "# first, we examine the settings used for our TFIDF vectorizer\n",
        "tfidf"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
              "                min_df=1, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
              "                smooth_idf=True,\n",
              "                stop_words=['that', \"that'll\", 'as', 'each', 'haven', 'other',\n",
              "                            \"you've\", \"wasn't\", 'at', 'his', 's', 'the', 'same',\n",
              "                            'your', \"isn't\", 'about', 'not', 'am', 'mightn',\n",
              "                            'of', 'or', \"she's\", 'against', 'do', 'my', 'most',\n",
              "                            \"weren't\", 'too', 'm', 'been', ...],\n",
              "                strip_accents=None, sublinear_tf=False,\n",
              "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
              "                vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fl623qxkLJiQ",
        "colab_type": "text"
      },
      "source": [
        "Based on https://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting, the equation used is:\n",
        "\n",
        "$\\text{tf-idf(t,d)}=\\text{tf(t,d)} \\times \\text{idf(t)}$\n",
        "\n",
        "Where:\n",
        "\n",
        "$\\text{idf}(t) = \\log{\\frac{n}{1+\\text{df}(t)}}$\n",
        "\n",
        "When smooth_idf=True, the TFIDF computed tries to avoid zero values by adding a 1:\n",
        "\n",
        "$\\text{idf}(t) = \\log{\\frac{1 + n}{1+\\text{df}(t)}} + 1$\n",
        "\n",
        "Where $n$ is the total number of documents in the document set, and $\\text{df}(t)$ is the number of documents in the document set that contain term $t$. The resulting tf-idf vectors are then normalized by the Euclidean norm:\n",
        "\n",
        "$v_{norm} = \\frac{v}{||v||_2} = \\frac{v}{\\sqrt{v{_1}^2 +\n",
        "v{_2}^2 + \\dots + v{_n}^2}}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT0suuTvLJiR",
        "colab_type": "code",
        "outputId": "79655132-3699-49a7-f7f7-9c60bb36c315",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "corpus"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This document is the first document.',\n",
              " 'This document is the second document.',\n",
              " 'And this is the third one.',\n",
              " 'Is this document the first document?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOfAtWXBLJiW",
        "colab_type": "code",
        "outputId": "7ab12ea7-8ac5-4493-b77f-5c9a44648422",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "# term frequency\n",
        "countvec = CountVectorizer(ngram_range=(1, 2), stop_words=list(stop))\n",
        "\n",
        "tf_sparse = countvec.fit_transform(corpus)\n",
        "tf = tf_sparse.todense()\n",
        "tf"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[2, 1, 0, 1, 1, 0, 0, 0, 0, 0],\n",
              "        [2, 0, 1, 0, 0, 0, 1, 1, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 1, 0, 0, 1, 1],\n",
              "        [2, 1, 0, 1, 1, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLBDe_GbLJic",
        "colab_type": "code",
        "outputId": "f435eb46-4e49-4aea-9d52-411320a91025",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# document frequency\n",
        "# the number of documents in the document set that contain term t\n",
        "# can be computed by inspecting how many non-zero counts there are in each column\n",
        "\n",
        "df = (tf > 0).sum(axis=0)\n",
        "df"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[3, 2, 1, 2, 2, 1, 1, 1, 1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihkjdtqKLJio",
        "colab_type": "code",
        "outputId": "6c02ddac-a70f-4ab5-eaae-253453f7df22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n = len(corpus)\n",
        "n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEQEIlfTLJiv",
        "colab_type": "code",
        "outputId": "1f7aa418-9357-4b12-e68b-d21309acd39f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# inverse document frequency (smooth_idf=True version)\n",
        "idf = np.log(n / (1 + df)) + 1\n",
        "idf"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[1.        , 1.28768207, 1.69314718, 1.28768207, 1.28768207,\n",
              "         1.69314718, 1.69314718, 1.69314718, 1.69314718, 1.69314718]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX9wUlJ9LJi1",
        "colab_type": "code",
        "outputId": "bd102083-a380-40b5-8f83-190f4fcf4026",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "source": [
        "# tf x idf\n",
        "# element-wise multiply\n",
        "tfidf_raw = np.multiply(tf, idf)\n",
        "pd.DataFrame(tfidf_raw, columns=vocab)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>document first</th>\n",
              "      <th>document second</th>\n",
              "      <th>first</th>\n",
              "      <th>first document</th>\n",
              "      <th>one</th>\n",
              "      <th>second</th>\n",
              "      <th>second document</th>\n",
              "      <th>third</th>\n",
              "      <th>third one</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>1.287682</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.287682</td>\n",
              "      <td>1.287682</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.693147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.693147</td>\n",
              "      <td>1.693147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.693147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.693147</td>\n",
              "      <td>1.693147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.0</td>\n",
              "      <td>1.287682</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.287682</td>\n",
              "      <td>1.287682</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   document  document first  ...     third  third one\n",
              "0       2.0        1.287682  ...  0.000000   0.000000\n",
              "1       2.0        0.000000  ...  0.000000   0.000000\n",
              "2       0.0        0.000000  ...  1.693147   1.693147\n",
              "3       2.0        1.287682  ...  0.000000   0.000000\n",
              "\n",
              "[4 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBzHAUpnLJi9",
        "colab_type": "code",
        "outputId": "54bbf73e-30f6-4b2e-c0a2-718c45e6f25f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# compute euclidean norm for each document\n",
        "v_norm = np.linalg.norm(tfidf_raw, axis=1)\n",
        "v_norm"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.99572618, 3.54968198, 2.93261694, 2.99572618])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EVLzY6vLJjB",
        "colab_type": "code",
        "outputId": "692a79a3-c40b-47c2-b752-87988c849060",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "# [:, None] allows tfidf_raw to be divided by each vector element\n",
        "# for example, first row will be divided by v_norm[0], second row by v_norm[1], etc\n",
        "tfidf = tfidf_raw / v_norm[:, None]\n",
        "tfidf"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0.66761776, 0.42983971, 0.        , 0.42983971, 0.42983971,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.56343076, 0.        , 0.4769856 , 0.        , 0.        ,\n",
              "         0.        , 0.4769856 , 0.4769856 , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.57735027, 0.        , 0.        , 0.57735027, 0.57735027],\n",
              "        [0.66761776, 0.42983971, 0.        , 0.42983971, 0.42983971,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP1A1arhLJjJ",
        "colab_type": "code",
        "outputId": "cb5ea159-7385-456d-e24d-428b8136a17b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "# compare with TfidfVectorizer's output\n",
        "result.todense()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0.6829022 , 0.42176004, 0.        , 0.42176004, 0.42176004,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.59329727, 0.        , 0.46475741, 0.        , 0.        ,\n",
              "         0.        , 0.46475741, 0.46475741, 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.57735027, 0.        , 0.        , 0.57735027, 0.57735027],\n",
              "        [0.6829022 , 0.42176004, 0.        , 0.42176004, 0.42176004,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzSVhMuFLJjO",
        "colab_type": "code",
        "outputId": "d3e8194f-b56d-4f88-ed3a-411fdf799d48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "# the values are within +/-0.02, possibly due to floating point rounding error\n",
        "abs(tfidf - result.todense())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0.01528444, 0.00807967, 0.        , 0.00807967, 0.00807967,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.02986651, 0.        , 0.01222819, 0.        , 0.        ,\n",
              "         0.        , 0.01222819, 0.01222819, 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.01528444, 0.00807967, 0.        , 0.00807967, 0.00807967,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KLTro19LJjT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C2orQjTLJjZ",
        "colab_type": "text"
      },
      "source": [
        "## Word2Vec\n",
        "\n",
        "Word2Vec generates word-vectors where vectors close together in vector space have similar meanings based on context, and word-vectors distant to each other have differing meanings.\n",
        "\n",
        "### Gensim\n",
        "\n",
        "Gensim is a Python library to train word vectors, and to load pre-trained word vectors.\n",
        "\n",
        "(You should already have Gensim installed if you followed the Workshop Setup Instructions.)\n",
        "\n",
        "https://radimrehurek.com/gensim/models/word2vec.html\n",
        "https://radimrehurek.com/gensim/models/keyedvectors.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9qi6NRZLJja",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7wy-w93LJja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "corpus = [\n",
        "    'Dashing through the snow',\n",
        "    'In a one-horse open sleigh',\n",
        "    'Over the fields we go',\n",
        "    'Laughing all the way',\n",
        "    'Bells on bob-tail ring',\n",
        "    'Making spirits bright',\n",
        "    'What fun it is to ride and sing a sleighing song tonight'\n",
        "]\n",
        "\n",
        "# split text into words\n",
        "corpus_tokens = [word_tokenize(doc.lower()) for doc in corpus]\n",
        "\n",
        "vector_size=10 # vector representation (typically about 50-100 for larger vocabs)\n",
        "\n",
        "window_size=3 # how many words to see around it (depending on task)\n",
        "\n",
        "# train\n",
        "word2vec = Word2Vec(corpus_tokens, size=vector_size, \n",
        "                    window=window_size,\n",
        "                    min_count=1, workers=4)\n",
        "\n",
        "# model.save(\"word2vec.model\") # save for use later"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LK-iMlxxLJjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lookup vector using wv\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwfmq4iHLJjg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# find similar words using most_similar\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGqZVSH2LJjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# inspect vocabulary using wv.vocab\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9cnIIG3LJjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get word vectors using vectors\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7BwKEUzLJjy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "2db294c2-108b-4f13-cc4a-b57f2e3a0b76"
      },
      "source": [
        "# To explore word vectors, you can plot them in 2d space\n",
        "# (Notice how useful PCA is?)\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "wv_2d = pca.fit_transform(word2vec.wv.vectors)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# scatter plot\n",
        "ax.scatter(wv_2d[:, 0], wv_2d[:, 1])\n",
        "\n",
        "# annotate each point using the words\n",
        "for i, word in enumerate(word2vec.wv.vocab):\n",
        "    ax.annotate(word, (wv_2d[i, 0], wv_2d[i, 1]))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD4CAYAAAAZ1BptAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPbNE4u9LJj2",
        "colab_type": "text"
      },
      "source": [
        "### Pre-trained Word2Vec models\n",
        "\n",
        "Instead of training your own word2vec, you can alternatively load the (large!) pre-trained models\n",
        "\n",
        "https://github.com/RaRe-Technologies/gensim-data\n",
        "\n",
        "These are most commonly used when training Neural Networks, because scikit-learn cannot handle non-scalar features well.  :("
      ]
    }
  ]
}