{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "\n",
    "1. Load MobileNet (smaller ImageNet pre-trained CNN), without classifier\n",
    "2. Train classifier with food pictures\n",
    "3. Fine-tune the last layers and classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Image loading and augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Source network\n",
    "from keras.applications import mobilenet\n",
    "\n",
    "# Target network's classifier\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "\n",
    "# training\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "ImageDataGenerator can be used for loading and augment images as a continuous stream.\n",
    "\n",
    "Augmentation (add variety to training set to avoid overfitting):\n",
    "-   rotation_range: randomly rotate image by some degrees\n",
    "-   horizontal_flip: randomly flip image side to side\n",
    "\n",
    "```\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=0.4,\n",
    "    horizontal_flip=True,\n",
    "    preprocessing_function=mobilenet.preprocess_input)\n",
    "\n",
    "X_train_gen = train_datagen.flow_from_directory('data/train',\n",
    "                                                target_size=(img_height, img_width),\n",
    "                                                batch_size=n_train_set)\n",
    "                                                \n",
    "batch = next(X_train_gen)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = img_width = 160\n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images\n",
    "labels = ['chapati', 'fishball_noodle', 'satay']\n",
    "\n",
    "train_folder = 'train'\n",
    "n_train_set = 45\n",
    "\n",
    "val_folder = 'validation'\n",
    "n_val_set = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing_function: use MobileNet's built-in function\n",
    "#                    why: ensures similar input as training\n",
    "#\n",
    "# Augmentation (add variety to training set to avoid overfitting):\n",
    "#   rotation_range: randomly rotate image by some degrees\n",
    "#   horizontal_flip: randomly flip image side to side (roti prata flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pre-trained Network\n",
    "\n",
    "https://keras.io/applications/#mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Classifier\n",
    "\n",
    "- Flatten\n",
    "- Dense layer (32 or 64)\n",
    "- Dropout to avoid overfitting\n",
    "- Dense (3)\n",
    "\n",
    "Rules of thumbs: https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune Classifier\n",
    "\n",
    "```\n",
    "featurizer = mobilenet.MobileNet(include_top=False,\n",
    "                                 input_shape=(img_width, img_height, channels))\n",
    "\n",
    "# Append the classifier we trained earlier to the featurizer\n",
    "combined_model = Model(inputs=featurizer.input,\n",
    "                       outputs=classifier(featurizer.output))\n",
    "\n",
    "# Freeze layers up to the last 7th layer (non-inclusive)\n",
    "for layer in combined_model.layers[:-7]:\n",
    "    layer.trainable = False # freeze\n",
    "\n",
    "combined_model.summary()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
